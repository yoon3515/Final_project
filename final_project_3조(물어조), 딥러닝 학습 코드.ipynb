{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a426542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#DEVICE = torch.device(\"cpu\") #cpu 전환\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06666a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 캐시 지우기\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635ad93",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e62dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(), #이미지 반전\n",
    "    transforms.RandomAffine(degrees=90, shear=10),#이미지 0~90도 회전, 0~10% 늘이기\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2), #밝기, 명도, 채도, 색조 랜덤 변경\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #이미지데이터 Nomalization\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DS = datasets.ImageFolder(\"./fish/20230504/20230504_data_set-1/train\", train_transform)\n",
    "val_DS = datasets.ImageFolder(\"./fish/20230504/20230504_data_set-1/val\", val_transform)\n",
    "test_DS = datasets.ImageFolder(\"./fish/20230504/20230504_data_set-1/test\", test_transform)\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=1, shuffle=True, num_workers=4)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "print(train_DS.class_to_idx)\n",
    "print('학습 데이터 개수/Batch:', len(train_DL), ', ','학습 데이터 전체 개수:', len(train_DS) )\n",
    "print('검증 데이터 개수/Batch:', len(val_DL), ', ','검증 데이터 전체 개수:', len(val_DS))\n",
    "print('테스트 데이터 개수/Batch:', len(test_DL), ', ','테스트 데이터 전체 개수:', len(test_DS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca788e31",
   "metadata": {},
   "source": [
    "## 학습 모델-1 (class화해서 customaizng가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec195f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fcs = nn.Sequential(nn.Linear(3*224*224, 1024),\n",
    "                                 nn.Sigmoid(),\n",
    "#                                  nn.ReLU(),\n",
    "                                 nn.Linear(1024, 1024),\n",
    "                                 nn.Sigmoid(),\n",
    "#                                  nn.ReLU(),\n",
    "                                 nn.Linear(1024, 1024),\n",
    "                                 nn.Sigmoid(),\n",
    "#                                  nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(1024, 11))\n",
    "#                                  *[i for _ in range(10) for i in [nn.Linear(1024, 1024),nn.ReLU()]],\n",
    "    def forward(self,x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "   #CNN \n",
    "    class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3,32,3, padding=1),\n",
    "                                   nn.ReLU())\n",
    "        self.Maxpool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32,64,3, padding=1),\n",
    "                                   nn.ReLU())\n",
    "        self.Maxpool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64,128,3, padding=1),\n",
    "                                  nn.ReLU())\n",
    "        self.Maxpool3 = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Sequential(nn.Linear(128*28*28, 256),\n",
    "                                 nn.ReLU(),\n",
    "#                                  nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(256, 11))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.Maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.Maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.Maxpool3(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db89146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP().to(DEVICE)\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2960a4f",
   "metadata": {},
   "source": [
    "### 학습 모델 -2 (class 설정안하고 기존에 있는 형태 바로 불러옴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet\n",
    "\n",
    "model = models.resnet101(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 11개로 교체하여 마지막 레이어 다시 학습\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(num_features, 512),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Dropout(0.5),\n",
    "#     nn.Linear(512, 11)\n",
    "# )\n",
    "model.fc = nn.Linear(num_features, 11)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#VGGNet\n",
    "model = models.vgg16(pretrained=True)\n",
    "num_features = model.classifier[-1].in_features\n",
    "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 11개로 교체하여 마지막 레이어 다시 학습\n",
    "model.classifier[-1] = nn.Linear(num_features, 11)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#MobileNet\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# 마지막 레이어 변경\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, 11)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d209983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff5df03b",
   "metadata": {},
   "source": [
    "## 학습하는 함수 및 시작 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_val(model, train_DL, val_DL, creiterion, optimizer, EPOCH):\n",
    "    \n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    train_acc_history, val_acc_history= [], []\n",
    "\n",
    "    for ep in range(EPOCH):\n",
    "        scheduler.step()\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        rcorr = 0 #running correct\n",
    "        rloss = 0 #running loss\n",
    "        for x_batch, y_batch in train_DL:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            #inference\n",
    "            y_hat = model(x_batch)\n",
    "            #loss\n",
    "            loss = criterion(y_hat, y_batch)\n",
    "            #update\n",
    "            optimizer.zero_grad() # gradient 누적을 막기 위한 초기화\n",
    "            loss.backward() # backpropagation\n",
    "            optimizer.step() # weight update\n",
    "            \n",
    "            #loss,acc 계산\n",
    "            loss_mini_batch = loss.item() * x_batch.shape[0] #batch loss # BATCH_SIZE를 곱하면 마지막 18개도 32개를 곱하니까..\n",
    "            rloss += loss_mini_batch #running loss\n",
    "            \n",
    "            _, predicted = torch.max(y_hat,1)\n",
    "            rcorr += torch.sum(predicted == y_batch).item() #얘는 그냥 각 데이터값 맞은 개수 다 더한거임\n",
    "        #print loss\n",
    "        train_rloss_e = rloss/len(train_DL.dataset) #epoch loss\n",
    "        train_racc_e = (rcorr/len(train_DL.dataset)) *100 #epoch acc\n",
    "        train_loss_history += [train_rloss_e] #append 개념\n",
    "        train_acc_history += [train_racc_e]\n",
    "        \n",
    "        \n",
    "        model.eval() #여기서 학습할때만 필요한 dropout이나 batchnorm등의 기능을 비활성화시킴\n",
    "        rcorr = 0 #running correct\n",
    "        rloss = 0 #running loss \n",
    "        for x_batch, y_batch in val_DL:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            \n",
    "            with torch.no_grad(): #gradient 계산 비활성화(no backpropagation??)\n",
    "                #inference\n",
    "                y_hat = model(x_batch)\n",
    "                #loss\n",
    "                loss= criterion(y_hat, y_batch)\n",
    "                \n",
    "                loss_mini_batch = loss.item() * x_batch.shape[0]\n",
    "                rloss += loss_mini_batch\n",
    "                _, predicted = torch.max(y_hat, 1)\n",
    "                rcorr += torch.sum(predicted == y_batch).item()\n",
    "                \n",
    "                val_rloss_e = rloss/len(val_DL.dataset)\n",
    "                val_racc_e = (rcorr/len(val_DL.dataset))*100\n",
    "                \n",
    "        val_loss_history += [val_rloss_e]\n",
    "        val_acc_history += [val_racc_e]\n",
    "        \n",
    "        \n",
    "        print('# ep {} Train  /// Loss: {:.4f} /// Acc: {:.4f}%'.format(ep+1, train_rloss_e, train_racc_e))\n",
    "        print('# ep {} Validation /// Loss: {:.4f} /// Acc: {:.4f}%'.format(ep+1, val_rloss_e, val_racc_e))\n",
    "        print(\"time :\", time.time() - start_time)\n",
    "        print(\"-\"*20)\n",
    "    \n",
    "    return train_loss_history, train_acc_history, val_loss_history, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdac3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시작 코드\n",
    "\n",
    "LR = 1e-2 \n",
    "EPOCH = 20 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9) \n",
    "# optimizer = optim.Adam(model.parameters(), lr=LR) \n",
    "\n",
    "train_loss_history, train_acc_history, val_loss_history, val_acc_history= train_with_val(model, train_DL, val_DL, criterion, optimizer, EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58568b",
   "metadata": {},
   "source": [
    "## 모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04a6cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##모델 저장하기\u001b[39;00m\n\u001b[1;32m      2\u001b[0m save_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fish/model/123.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model,save_model_path)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fish/model/1004.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#모델 저장하기\n",
    "save_model_path = \"./fish/model/123.pt\"\n",
    "torch.save(model,save_model_path)\n",
    "\n",
    "#모델 acurracy, Loss dataframe으로 저장하기, (학습 직후에만 가능함)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'train_loss_history': train_loss_history,\n",
    "                   'train_acc_history': train_acc_history,\n",
    "                   'val_loss_history': val_loss_history,\n",
    "                   'val_acc_history': val_acc_history})\n",
    "df.to_csv('./fish/model/history_123.csv', index=False)\n",
    "\n",
    "\n",
    "#모델 불러오기\n",
    "model=torch.load(\"./fish/model/1004.pt\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2162fee",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch별 acurracy, loss 구하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax1 = ax2.twinx()\n",
    "\n",
    "ax1.plot(range(1, len(train_acc_history)+1), train_acc_history, label='Train Acc', color='skyblue')\n",
    "ax1.plot(range(1, len(train_acc_history)+1),val_acc_history, label='Val Acc', color='orange')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_ylim([0, 100])\n",
    "\n",
    "ax2.plot(range(1, len(train_acc_history)+1), train_loss_history, linestyle='-',label='Train Loss', color='skyblue')\n",
    "ax2.plot(range(1, len(train_acc_history)+1), val_loss_history, linestyle='-', label='Val Loss', color='orange')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylim([0, 10])\n",
    "ax2.set_xlim([1, 10])\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines = lines1 + lines2\n",
    "labels =   labels2\n",
    "fig.legend(lines, labels, loc='upper right')\n",
    "plt.xticks(np.arange(0, 21, 1))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 및 사이킷런 classification_report 관련 함수\n",
    "#테스트 데이터 넣어서 평가\n",
    "def get_conf(model, test_DL):\n",
    "    N = len(test_DL.dataset.classes)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        confusion = torch.zeros(N,N)\n",
    "        for x_batch, y_batch in test_DL:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            # inference\n",
    "            y_hat = model(x_batch)\n",
    "            # accuracy\n",
    "            pred = y_hat.argmax(dim=1)\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            for i in range(y_batch.shape[0]):\n",
    "                confusion[pred[i], y_batch[i]] += 1\n",
    "            # confusion[pred, y_batch] += 1\n",
    "        \n",
    "    confusion = confusion.numpy()\n",
    "\n",
    "    return confusion, y_pred, y_true #confusion은 confusion matrix에 사용, y_pred, y_true는 classes_report에 사용\n",
    "\n",
    "#confusion matrix 그리기 함수\n",
    "def plot_confusion_matrix(confusion, classes=None):\n",
    "    N = confusion.shape[0]\n",
    "    accuracy=np.trace(confusion)/np.sum(confusion) * 100\n",
    "    \n",
    "    confusion = confusion/np.sum(confusion, axis=0)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(confusion, cmap=\"Blues\")\n",
    "    plt.title(\"\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            plt.text(j,i, round(confusion[i,j],2), \n",
    "                     horizontalalignment=\"center\", \n",
    "                     color=\"white\" if confusion[i,j] > np.max(confusion) / 1.5 else \"black\")\n",
    "\n",
    "    if classes is not None:\n",
    "        plt.xticks(range(N), classes)\n",
    "        plt.yticks(range(N), classes)\n",
    "    else:\n",
    "        plt.xticks(range(N))\n",
    "        plt.yticks(range(N))\n",
    "\n",
    "    plt.ylabel(\"Predicted label\", fontsize=20)\n",
    "    plt.xlabel(f\"True label\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 실행\n",
    "confusion, y_pred, y_true = get_conf(load_model, test_DL)\n",
    "plot_confusion_matrix(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사이킷런 classification_report 실행\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=test_DS.classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genietfgpu",
   "language": "python",
   "name": "genietfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
